# Experiment Configuration
# Single behaviour (grammar_agreement) for end-to-end CSD3 testing

# Random seeds
seeds:
  prompt_generation: 42
  intervention_sampling: 456
  torch_seed: 789

# Model configuration
model:
  name: "Qwen/Qwen3-4B-Instruct-2507"
  revision: "main"
  dtype: "float32"      # Use float32 for CPU (bfloat16 is GPU-optimized)
  device: "cpu"         # Force CPU for initial testing
  max_length: 512
  trust_remote_code: true

# Behaviours
behaviours:
  grammar_agreement:
    train_size: 80
    test_size: 100
    min_logit_diff: 2.0
    success_threshold: 0.80
    description: "Subject-verb number agreement (singular/plural)"

  physics_scalar_vector_operator:
    train_size: 80
    test_size: 20
    min_logit_diff: 1.5
    success_threshold: 0.75
    description: "Classify operators/quantities as scalar vs vector (Type 3: Abstraction)"

# Activation capture
activations:
  layer_range: [15, 21]   # Middle layers: 15-20 (6 layers, matches transcoder_config middle range)
  token_positions: "last"
  batch_size: 2           # Smaller batch for CPU memory

# Transcoder settings
transcoder:
  model_size: "4b"
  config_file: "configs/transcoder_config.yaml"
  lazy_load: true

# Attribution graph
attribution:
  method: "gradient"
  top_k_edges: 10
  attribution_threshold: 0.01
  prune_nodes_min_edges: 2

# Intervention experiments
interventions:
  ablation:
    top_n_features: [1, 3, 5, 10]
    n_control_samples: 20

  patching:
    swap_token_positions: "subject"
    n_pairs: 40

# Paths
paths:
  prompts: "data/prompts"
  activations: "data/activations"
  results: "data/results"
  transcoders_cache: "~/.cache/transcoders"
  figures: "figures"

# Computational limits
compute:
  max_activation_memory_gb: 10
  use_cpu_if_no_gpu: true
  num_workers: 4
